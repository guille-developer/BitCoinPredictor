{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bitcoin predictor funcional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVZ8bXQsTgNT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAdRYSJ4TS1n",
        "outputId": "66f17d65-c223-4be1-f096-acf974ca34a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        }
      },
      "source": [
        "!pip3 install sklearn tensorflow matplotlib numpy pandas yahoo_fin\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: yahoo_fin in /usr/local/lib/python3.6/dist-packages (0.8.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.31.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (49.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1BFgLF4SqXn"
      },
      "source": [
        "import os\n",
        "import time\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import RNN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Window size or the sequence length\n",
        "N_STEPS = 30\n",
        "# Lookup step, 1 is the next day\n",
        "LOOKUP_STEP = 30\n",
        "\n",
        "# test ratio size, 0.2 is 20%\n",
        "TEST_SIZE = 0.2\n",
        "# features to use\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "# date now\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "### model parameters\n",
        "end_date=\"08/01/2020\"\n",
        "N_LAYERS = 3\n",
        "# LSTM cell\n",
        "CELL = LSTM\n",
        "# 256 LSTM neurons\n",
        "UNITS = 256\n",
        "# 40% dropout\n",
        "DROPOUT = 0.4\n",
        "# whether to use bidirectional RNNs\n",
        "BIDIRECTIONAL = False\n",
        "\n",
        "### training parameters\n",
        "\n",
        "# mean absolute error loss\n",
        "# LOSS = \"mae\"\n",
        "# huber loss\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"Adam\"\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 400\n",
        "SHUFFLE = False\n",
        "# Apple stock market\n",
        "ticker = \"BBY\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "# model name to save, making it as unique as possible based on parameters\n",
        "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5JhjC2NvHo3"
      },
      "source": [
        "# Sección nueva"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D80j4T9uUeS1"
      },
      "source": [
        "Set# Sección nueva"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrShQZYVSvUp"
      },
      "source": [
        "\n",
        "\n",
        "# set seed, so we can get the same results after rerunning several times\n",
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)\n",
        "\n",
        "\n",
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    \"\"\"\n",
        "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
        "    Params:\n",
        "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
        "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
        "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
        "        shuffle (bool): whether to shuffle the data, default is True\n",
        "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
        "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
        "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
        "    \"\"\"\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker, end_date=end_date)\n",
        "        #df = si.get_data(ticker)\n",
        "\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    else:\n",
        "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
        "\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "    df['future']= df['future'].fillna(df['adjclose'][-1])\n",
        "    #print(df['adjclose'][-1])\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    \n",
        "    # drop NaNs\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "\n",
        "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 59 (that is 50+10-1) length\n",
        "    # this last_sequence will be used to predict in future dates that are not available in the dataset\n",
        "    last_sequence = list(sequences) + list(last_sequence)\n",
        "    # shift the last sequence by -1\n",
        "    last_sequence = np.array(pd.DataFrame(last_sequence).shift(-1).dropna())\n",
        "    # add to result\n",
        "    result['last_sequence'] = last_sequence\n",
        "    \n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    # convert to numpy arrays\n",
        "    print(len(y))\n",
        "    \n",
        "    s = len(y) - lookup_step\n",
        "    X = np.array(X)\n",
        "    print(np.array(X).shape)\n",
        "    y = np.array(y)\n",
        "    print(s)\n",
        "    # reshape X to fit the neural network\n",
        "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
        "    result[\"x\"] = X\n",
        "    X = X[:s]\n",
        "    y = y[:s]\n",
        "    # split the dataset\n",
        "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
        "                                                                                test_size=test_size, shuffle=shuffle)\n",
        "    # return the result\n",
        "    return result\n",
        "\n",
        "\n",
        "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK_7-SXRPzFF",
        "outputId": "b9963373-3a14-47eb-c647-1e265fbe5ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8866\n",
            "(8866, 30, 5)\n",
            "8836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2uaJ1paP1Jz",
        "outputId": "3d1179b9-2514-4b05-be70-8c30a55f99c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[\"y_train\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7068,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EUZ2LrUSzWd",
        "outputId": "4fefdb07-7f82-42b8-cb7e-c800e3f64fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# create these folders if they does not exist\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")\n",
        "\n",
        "# load the data\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
        "\n",
        "# save the dataframe\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "# some tensorflow callbacks\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                    verbose=1)\n",
        "\n",
        "model.save(os.path.join(\"results\", model_name) + \".h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8866\n",
            "(8866, 30, 5)\n",
            "8836\n",
            "Epoch 1/400\n",
            "  2/442 [..............................] - ETA: 57s - loss: 0.0197 - mean_absolute_error: 0.1349WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0154s vs `on_train_batch_end` time: 0.2450s). Check your callbacks.\n",
            "440/442 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0422\n",
            "Epoch 00001: val_loss improved from inf to 0.00129, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 5s 11ms/step - loss: 0.0023 - mean_absolute_error: 0.0422 - val_loss: 0.0013 - val_mean_absolute_error: 0.0317\n",
            "Epoch 2/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0362\n",
            "Epoch 00002: val_loss improved from 0.00129 to 0.00118, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0015 - mean_absolute_error: 0.0362 - val_loss: 0.0012 - val_mean_absolute_error: 0.0300\n",
            "Epoch 3/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0343\n",
            "Epoch 00003: val_loss improved from 0.00118 to 0.00118, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0013 - mean_absolute_error: 0.0344 - val_loss: 0.0012 - val_mean_absolute_error: 0.0334\n",
            "Epoch 4/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0335\n",
            "Epoch 00004: val_loss improved from 0.00118 to 0.00104, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0012 - mean_absolute_error: 0.0335 - val_loss: 0.0010 - val_mean_absolute_error: 0.0284\n",
            "Epoch 5/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0324\n",
            "Epoch 00005: val_loss improved from 0.00104 to 0.00092, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0012 - mean_absolute_error: 0.0324 - val_loss: 9.1894e-04 - val_mean_absolute_error: 0.0251\n",
            "Epoch 6/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0308\n",
            "Epoch 00006: val_loss improved from 0.00092 to 0.00087, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0010 - mean_absolute_error: 0.0308 - val_loss: 8.6887e-04 - val_mean_absolute_error: 0.0261\n",
            "Epoch 7/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0313\n",
            "Epoch 00007: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0011 - mean_absolute_error: 0.0313 - val_loss: 8.8444e-04 - val_mean_absolute_error: 0.0247\n",
            "Epoch 8/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0318\n",
            "Epoch 00008: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0011 - mean_absolute_error: 0.0318 - val_loss: 8.8629e-04 - val_mean_absolute_error: 0.0263\n",
            "Epoch 9/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0307\n",
            "Epoch 00009: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0010 - mean_absolute_error: 0.0307 - val_loss: 0.0012 - val_mean_absolute_error: 0.0347\n",
            "Epoch 10/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0315\n",
            "Epoch 00010: val_loss improved from 0.00087 to 0.00087, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0011 - mean_absolute_error: 0.0315 - val_loss: 8.6821e-04 - val_mean_absolute_error: 0.0238\n",
            "Epoch 11/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 9.9995e-04 - mean_absolute_error: 0.0306\n",
            "Epoch 00011: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0010 - mean_absolute_error: 0.0306 - val_loss: 9.8807e-04 - val_mean_absolute_error: 0.0298\n",
            "Epoch 12/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 9.9534e-04 - mean_absolute_error: 0.0303\n",
            "Epoch 00012: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.9336e-04 - mean_absolute_error: 0.0303 - val_loss: 9.6318e-04 - val_mean_absolute_error: 0.0322\n",
            "Epoch 13/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0306\n",
            "Epoch 00013: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 0.0010 - mean_absolute_error: 0.0305 - val_loss: 0.0011 - val_mean_absolute_error: 0.0301\n",
            "Epoch 14/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 9.0044e-04 - mean_absolute_error: 0.0292\n",
            "Epoch 00014: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.0044e-04 - mean_absolute_error: 0.0292 - val_loss: 0.0011 - val_mean_absolute_error: 0.0277\n",
            "Epoch 15/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 9.4296e-04 - mean_absolute_error: 0.0301\n",
            "Epoch 00015: val_loss did not improve from 0.00087\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.5494e-04 - mean_absolute_error: 0.0302 - val_loss: 8.9329e-04 - val_mean_absolute_error: 0.0244\n",
            "Epoch 16/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 9.2436e-04 - mean_absolute_error: 0.0292\n",
            "Epoch 00016: val_loss improved from 0.00087 to 0.00085, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.2377e-04 - mean_absolute_error: 0.0292 - val_loss: 8.4605e-04 - val_mean_absolute_error: 0.0248\n",
            "Epoch 17/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 8.9885e-04 - mean_absolute_error: 0.0288\n",
            "Epoch 00017: val_loss did not improve from 0.00085\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.0073e-04 - mean_absolute_error: 0.0289 - val_loss: 8.8240e-04 - val_mean_absolute_error: 0.0257\n",
            "Epoch 18/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 9.5568e-04 - mean_absolute_error: 0.0301\n",
            "Epoch 00018: val_loss did not improve from 0.00085\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.5229e-04 - mean_absolute_error: 0.0301 - val_loss: 8.6603e-04 - val_mean_absolute_error: 0.0287\n",
            "Epoch 19/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 9.3509e-04 - mean_absolute_error: 0.0301\n",
            "Epoch 00019: val_loss improved from 0.00085 to 0.00082, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.3914e-04 - mean_absolute_error: 0.0301 - val_loss: 8.2249e-04 - val_mean_absolute_error: 0.0237\n",
            "Epoch 20/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 9.3646e-04 - mean_absolute_error: 0.0296\n",
            "Epoch 00020: val_loss did not improve from 0.00082\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.3351e-04 - mean_absolute_error: 0.0296 - val_loss: 9.7891e-04 - val_mean_absolute_error: 0.0316\n",
            "Epoch 21/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 8.6934e-04 - mean_absolute_error: 0.0290\n",
            "Epoch 00021: val_loss improved from 0.00082 to 0.00079, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.7479e-04 - mean_absolute_error: 0.0290 - val_loss: 7.8820e-04 - val_mean_absolute_error: 0.0248\n",
            "Epoch 22/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 9.1330e-04 - mean_absolute_error: 0.0296\n",
            "Epoch 00022: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.1428e-04 - mean_absolute_error: 0.0296 - val_loss: 8.2016e-04 - val_mean_absolute_error: 0.0248\n",
            "Epoch 23/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 8.7930e-04 - mean_absolute_error: 0.0288\n",
            "Epoch 00023: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.7641e-04 - mean_absolute_error: 0.0288 - val_loss: 8.0821e-04 - val_mean_absolute_error: 0.0258\n",
            "Epoch 24/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 8.9121e-04 - mean_absolute_error: 0.0289\n",
            "Epoch 00024: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.9316e-04 - mean_absolute_error: 0.0290 - val_loss: 8.8043e-04 - val_mean_absolute_error: 0.0264\n",
            "Epoch 25/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 9.0465e-04 - mean_absolute_error: 0.0289\n",
            "Epoch 00025: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 9.0597e-04 - mean_absolute_error: 0.0289 - val_loss: 0.0013 - val_mean_absolute_error: 0.0389\n",
            "Epoch 26/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 8.7223e-04 - mean_absolute_error: 0.0285\n",
            "Epoch 00026: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.7525e-04 - mean_absolute_error: 0.0285 - val_loss: 8.5321e-04 - val_mean_absolute_error: 0.0270\n",
            "Epoch 27/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 8.5558e-04 - mean_absolute_error: 0.0285\n",
            "Epoch 00027: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.5753e-04 - mean_absolute_error: 0.0285 - val_loss: 0.0011 - val_mean_absolute_error: 0.0275\n",
            "Epoch 28/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 8.3947e-04 - mean_absolute_error: 0.0287\n",
            "Epoch 00028: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.3988e-04 - mean_absolute_error: 0.0287 - val_loss: 8.1911e-04 - val_mean_absolute_error: 0.0267\n",
            "Epoch 29/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 8.4519e-04 - mean_absolute_error: 0.0281\n",
            "Epoch 00029: val_loss did not improve from 0.00079\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.4139e-04 - mean_absolute_error: 0.0281 - val_loss: 8.3811e-04 - val_mean_absolute_error: 0.0245\n",
            "Epoch 30/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 8.6694e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 00030: val_loss improved from 0.00079 to 0.00076, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.6734e-04 - mean_absolute_error: 0.0284 - val_loss: 7.5668e-04 - val_mean_absolute_error: 0.0234\n",
            "Epoch 31/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 8.4584e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 00031: val_loss did not improve from 0.00076\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.4626e-04 - mean_absolute_error: 0.0283 - val_loss: 8.7512e-04 - val_mean_absolute_error: 0.0246\n",
            "Epoch 32/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 8.7423e-04 - mean_absolute_error: 0.0285\n",
            "Epoch 00032: val_loss did not improve from 0.00076\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.7725e-04 - mean_absolute_error: 0.0285 - val_loss: 9.5930e-04 - val_mean_absolute_error: 0.0271\n",
            "Epoch 33/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 8.6963e-04 - mean_absolute_error: 0.0287\n",
            "Epoch 00033: val_loss did not improve from 0.00076\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.6921e-04 - mean_absolute_error: 0.0287 - val_loss: 8.2168e-04 - val_mean_absolute_error: 0.0251\n",
            "Epoch 34/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 8.3193e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 00034: val_loss did not improve from 0.00076\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.3193e-04 - mean_absolute_error: 0.0283 - val_loss: 8.2192e-04 - val_mean_absolute_error: 0.0269\n",
            "Epoch 35/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 8.2731e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 00035: val_loss did not improve from 0.00076\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.2689e-04 - mean_absolute_error: 0.0283 - val_loss: 0.0011 - val_mean_absolute_error: 0.0258\n",
            "Epoch 36/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 8.2173e-04 - mean_absolute_error: 0.0283\n",
            "Epoch 00036: val_loss improved from 0.00076 to 0.00074, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.2094e-04 - mean_absolute_error: 0.0283 - val_loss: 7.4221e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 37/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 7.9978e-04 - mean_absolute_error: 0.0272\n",
            "Epoch 00037: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.9769e-04 - mean_absolute_error: 0.0272 - val_loss: 8.4674e-04 - val_mean_absolute_error: 0.0279\n",
            "Epoch 38/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 8.0089e-04 - mean_absolute_error: 0.0274\n",
            "Epoch 00038: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.9965e-04 - mean_absolute_error: 0.0274 - val_loss: 7.9627e-04 - val_mean_absolute_error: 0.0271\n",
            "Epoch 39/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 8.3960e-04 - mean_absolute_error: 0.0281\n",
            "Epoch 00039: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.3909e-04 - mean_absolute_error: 0.0281 - val_loss: 8.3668e-04 - val_mean_absolute_error: 0.0254\n",
            "Epoch 40/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 7.6550e-04 - mean_absolute_error: 0.0267\n",
            "Epoch 00040: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.6638e-04 - mean_absolute_error: 0.0267 - val_loss: 8.9312e-04 - val_mean_absolute_error: 0.0275\n",
            "Epoch 41/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 8.1116e-04 - mean_absolute_error: 0.0272\n",
            "Epoch 00041: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.1094e-04 - mean_absolute_error: 0.0272 - val_loss: 8.1081e-04 - val_mean_absolute_error: 0.0256\n",
            "Epoch 42/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 8.0587e-04 - mean_absolute_error: 0.0272\n",
            "Epoch 00042: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.1329e-04 - mean_absolute_error: 0.0272 - val_loss: 0.0010 - val_mean_absolute_error: 0.0271\n",
            "Epoch 43/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.7696e-04 - mean_absolute_error: 0.0267\n",
            "Epoch 00043: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.7530e-04 - mean_absolute_error: 0.0267 - val_loss: 8.0796e-04 - val_mean_absolute_error: 0.0247\n",
            "Epoch 44/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.6350e-04 - mean_absolute_error: 0.0266\n",
            "Epoch 00044: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.6263e-04 - mean_absolute_error: 0.0265 - val_loss: 7.4589e-04 - val_mean_absolute_error: 0.0224\n",
            "Epoch 45/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 8.0980e-04 - mean_absolute_error: 0.0272\n",
            "Epoch 00045: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 8.0609e-04 - mean_absolute_error: 0.0272 - val_loss: 7.7227e-04 - val_mean_absolute_error: 0.0225\n",
            "Epoch 46/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 7.5417e-04 - mean_absolute_error: 0.0265\n",
            "Epoch 00046: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.5326e-04 - mean_absolute_error: 0.0265 - val_loss: 8.9094e-04 - val_mean_absolute_error: 0.0258\n",
            "Epoch 47/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 7.6492e-04 - mean_absolute_error: 0.0264\n",
            "Epoch 00047: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.6415e-04 - mean_absolute_error: 0.0264 - val_loss: 8.3837e-04 - val_mean_absolute_error: 0.0238\n",
            "Epoch 48/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.8374e-04 - mean_absolute_error: 0.0269\n",
            "Epoch 00048: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.8330e-04 - mean_absolute_error: 0.0269 - val_loss: 8.1716e-04 - val_mean_absolute_error: 0.0264\n",
            "Epoch 49/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.4213e-04 - mean_absolute_error: 0.0265\n",
            "Epoch 00049: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.4388e-04 - mean_absolute_error: 0.0265 - val_loss: 8.0975e-04 - val_mean_absolute_error: 0.0251\n",
            "Epoch 50/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 7.6366e-04 - mean_absolute_error: 0.0264\n",
            "Epoch 00050: val_loss did not improve from 0.00074\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.6524e-04 - mean_absolute_error: 0.0264 - val_loss: 9.0565e-04 - val_mean_absolute_error: 0.0256\n",
            "Epoch 51/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.7464e-04 - mean_absolute_error: 0.0268\n",
            "Epoch 00051: val_loss improved from 0.00074 to 0.00073, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.7595e-04 - mean_absolute_error: 0.0269 - val_loss: 7.2764e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 52/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 7.4397e-04 - mean_absolute_error: 0.0263\n",
            "Epoch 00052: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.4544e-04 - mean_absolute_error: 0.0263 - val_loss: 8.4959e-04 - val_mean_absolute_error: 0.0293\n",
            "Epoch 53/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.3665e-04 - mean_absolute_error: 0.0261\n",
            "Epoch 00053: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.3887e-04 - mean_absolute_error: 0.0261 - val_loss: 9.0362e-04 - val_mean_absolute_error: 0.0287\n",
            "Epoch 54/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 7.3877e-04 - mean_absolute_error: 0.0263\n",
            "Epoch 00054: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.3831e-04 - mean_absolute_error: 0.0263 - val_loss: 7.9578e-04 - val_mean_absolute_error: 0.0251\n",
            "Epoch 55/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 7.6051e-04 - mean_absolute_error: 0.0266\n",
            "Epoch 00055: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.6051e-04 - mean_absolute_error: 0.0266 - val_loss: 7.7323e-04 - val_mean_absolute_error: 0.0243\n",
            "Epoch 56/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 7.7299e-04 - mean_absolute_error: 0.0266\n",
            "Epoch 00056: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.7304e-04 - mean_absolute_error: 0.0266 - val_loss: 8.9307e-04 - val_mean_absolute_error: 0.0252\n",
            "Epoch 57/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 7.5044e-04 - mean_absolute_error: 0.0263\n",
            "Epoch 00057: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.4854e-04 - mean_absolute_error: 0.0263 - val_loss: 7.6472e-04 - val_mean_absolute_error: 0.0239\n",
            "Epoch 58/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 7.2655e-04 - mean_absolute_error: 0.0259\n",
            "Epoch 00058: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2626e-04 - mean_absolute_error: 0.0259 - val_loss: 7.4989e-04 - val_mean_absolute_error: 0.0254\n",
            "Epoch 59/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 7.2149e-04 - mean_absolute_error: 0.0259\n",
            "Epoch 00059: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2149e-04 - mean_absolute_error: 0.0259 - val_loss: 7.5036e-04 - val_mean_absolute_error: 0.0232\n",
            "Epoch 60/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.3294e-04 - mean_absolute_error: 0.0259\n",
            "Epoch 00060: val_loss improved from 0.00073 to 0.00073, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.3320e-04 - mean_absolute_error: 0.0259 - val_loss: 7.2717e-04 - val_mean_absolute_error: 0.0230\n",
            "Epoch 61/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 7.2937e-04 - mean_absolute_error: 0.0258\n",
            "Epoch 00061: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2889e-04 - mean_absolute_error: 0.0258 - val_loss: 8.2964e-04 - val_mean_absolute_error: 0.0248\n",
            "Epoch 62/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 7.1576e-04 - mean_absolute_error: 0.0258\n",
            "Epoch 00062: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.1583e-04 - mean_absolute_error: 0.0258 - val_loss: 8.4803e-04 - val_mean_absolute_error: 0.0249\n",
            "Epoch 63/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 7.1660e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00063: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2037e-04 - mean_absolute_error: 0.0257 - val_loss: 7.5218e-04 - val_mean_absolute_error: 0.0248\n",
            "Epoch 64/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 7.2974e-04 - mean_absolute_error: 0.0262\n",
            "Epoch 00064: val_loss did not improve from 0.00073\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.3151e-04 - mean_absolute_error: 0.0262 - val_loss: 7.3237e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 65/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 7.3726e-04 - mean_absolute_error: 0.0259\n",
            "Epoch 00065: val_loss improved from 0.00073 to 0.00067, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.3704e-04 - mean_absolute_error: 0.0259 - val_loss: 6.7377e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 66/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 7.1543e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00066: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.1374e-04 - mean_absolute_error: 0.0256 - val_loss: 6.8750e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 67/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 7.3756e-04 - mean_absolute_error: 0.0258\n",
            "Epoch 00067: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.3774e-04 - mean_absolute_error: 0.0259 - val_loss: 7.0916e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 68/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 7.1525e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00068: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.1349e-04 - mean_absolute_error: 0.0256 - val_loss: 6.8104e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 69/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 7.2701e-04 - mean_absolute_error: 0.0261\n",
            "Epoch 00069: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2779e-04 - mean_absolute_error: 0.0261 - val_loss: 7.9319e-04 - val_mean_absolute_error: 0.0283\n",
            "Epoch 70/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 7.0953e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00070: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.0896e-04 - mean_absolute_error: 0.0256 - val_loss: 7.6452e-04 - val_mean_absolute_error: 0.0255\n",
            "Epoch 71/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.0109e-04 - mean_absolute_error: 0.0254\n",
            "Epoch 00071: val_loss improved from 0.00067 to 0.00067, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.0103e-04 - mean_absolute_error: 0.0254 - val_loss: 6.7153e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 72/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 7.2090e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00072: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2138e-04 - mean_absolute_error: 0.0256 - val_loss: 7.5281e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 73/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.9729e-04 - mean_absolute_error: 0.0252\n",
            "Epoch 00073: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.0280e-04 - mean_absolute_error: 0.0252 - val_loss: 7.9396e-04 - val_mean_absolute_error: 0.0236\n",
            "Epoch 74/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 7.2761e-04 - mean_absolute_error: 0.0259\n",
            "Epoch 00074: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2761e-04 - mean_absolute_error: 0.0259 - val_loss: 9.5467e-04 - val_mean_absolute_error: 0.0260\n",
            "Epoch 75/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 6.9743e-04 - mean_absolute_error: 0.0253\n",
            "Epoch 00075: val_loss did not improve from 0.00067\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9790e-04 - mean_absolute_error: 0.0253 - val_loss: 7.0046e-04 - val_mean_absolute_error: 0.0227\n",
            "Epoch 76/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 7.0038e-04 - mean_absolute_error: 0.0255\n",
            "Epoch 00076: val_loss improved from 0.00067 to 0.00066, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9809e-04 - mean_absolute_error: 0.0255 - val_loss: 6.5595e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 77/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 7.0756e-04 - mean_absolute_error: 0.0255\n",
            "Epoch 00077: val_loss did not improve from 0.00066\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.0778e-04 - mean_absolute_error: 0.0255 - val_loss: 7.3026e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 78/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.8938e-04 - mean_absolute_error: 0.0252\n",
            "Epoch 00078: val_loss did not improve from 0.00066\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.8818e-04 - mean_absolute_error: 0.0252 - val_loss: 6.8783e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 79/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 6.7725e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 00079: val_loss did not improve from 0.00066\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.7895e-04 - mean_absolute_error: 0.0252 - val_loss: 6.6812e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 80/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.9346e-04 - mean_absolute_error: 0.0254\n",
            "Epoch 00080: val_loss did not improve from 0.00066\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9285e-04 - mean_absolute_error: 0.0254 - val_loss: 9.0715e-04 - val_mean_absolute_error: 0.0290\n",
            "Epoch 81/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 7.1820e-04 - mean_absolute_error: 0.0254\n",
            "Epoch 00081: val_loss did not improve from 0.00066\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 7.1757e-04 - mean_absolute_error: 0.0254 - val_loss: 7.0368e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 82/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.9052e-04 - mean_absolute_error: 0.0256\n",
            "Epoch 00082: val_loss improved from 0.00066 to 0.00064, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9012e-04 - mean_absolute_error: 0.0256 - val_loss: 6.4112e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 83/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.9636e-04 - mean_absolute_error: 0.0254\n",
            "Epoch 00083: val_loss did not improve from 0.00064\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9636e-04 - mean_absolute_error: 0.0254 - val_loss: 7.4040e-04 - val_mean_absolute_error: 0.0224\n",
            "Epoch 84/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.9083e-04 - mean_absolute_error: 0.0253\n",
            "Epoch 00084: val_loss did not improve from 0.00064\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9245e-04 - mean_absolute_error: 0.0253 - val_loss: 7.0608e-04 - val_mean_absolute_error: 0.0232\n",
            "Epoch 85/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.8375e-04 - mean_absolute_error: 0.0250\n",
            "Epoch 00085: val_loss did not improve from 0.00064\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.8376e-04 - mean_absolute_error: 0.0251 - val_loss: 6.8328e-04 - val_mean_absolute_error: 0.0218\n",
            "Epoch 86/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 6.9247e-04 - mean_absolute_error: 0.0252\n",
            "Epoch 00086: val_loss did not improve from 0.00064\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9618e-04 - mean_absolute_error: 0.0253 - val_loss: 6.8172e-04 - val_mean_absolute_error: 0.0233\n",
            "Epoch 87/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.5672e-04 - mean_absolute_error: 0.0247\n",
            "Epoch 00087: val_loss did not improve from 0.00064\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.6180e-04 - mean_absolute_error: 0.0248 - val_loss: 6.4508e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 88/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 7.2313e-04 - mean_absolute_error: 0.0258\n",
            "Epoch 00088: val_loss did not improve from 0.00064\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 7.2434e-04 - mean_absolute_error: 0.0258 - val_loss: 7.3806e-04 - val_mean_absolute_error: 0.0234\n",
            "Epoch 89/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 6.8642e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 00089: val_loss did not improve from 0.00064\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.9001e-04 - mean_absolute_error: 0.0251 - val_loss: 6.7985e-04 - val_mean_absolute_error: 0.0218\n",
            "Epoch 90/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.7592e-04 - mean_absolute_error: 0.0250\n",
            "Epoch 00090: val_loss improved from 0.00064 to 0.00062, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.7539e-04 - mean_absolute_error: 0.0250 - val_loss: 6.1656e-04 - val_mean_absolute_error: 0.0222\n",
            "Epoch 91/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.6769e-04 - mean_absolute_error: 0.0250\n",
            "Epoch 00091: val_loss did not improve from 0.00062\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.6705e-04 - mean_absolute_error: 0.0250 - val_loss: 6.5727e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 92/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.9104e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 00092: val_loss did not improve from 0.00062\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.9300e-04 - mean_absolute_error: 0.0252 - val_loss: 7.3672e-04 - val_mean_absolute_error: 0.0230\n",
            "Epoch 93/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.8222e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 00093: val_loss did not improve from 0.00062\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.8193e-04 - mean_absolute_error: 0.0251 - val_loss: 6.8633e-04 - val_mean_absolute_error: 0.0218\n",
            "Epoch 94/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 6.7106e-04 - mean_absolute_error: 0.0251\n",
            "Epoch 00094: val_loss improved from 0.00062 to 0.00061, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.7236e-04 - mean_absolute_error: 0.0251 - val_loss: 6.0851e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 95/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.7378e-04 - mean_absolute_error: 0.0248\n",
            "Epoch 00095: val_loss did not improve from 0.00061\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.7323e-04 - mean_absolute_error: 0.0248 - val_loss: 7.1583e-04 - val_mean_absolute_error: 0.0231\n",
            "Epoch 96/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.5490e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 00096: val_loss improved from 0.00061 to 0.00059, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.5490e-04 - mean_absolute_error: 0.0245 - val_loss: 5.8604e-04 - val_mean_absolute_error: 0.0208\n",
            "Epoch 97/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.6491e-04 - mean_absolute_error: 0.0249\n",
            "Epoch 00097: val_loss did not improve from 0.00059\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.6491e-04 - mean_absolute_error: 0.0249 - val_loss: 6.2014e-04 - val_mean_absolute_error: 0.0219\n",
            "Epoch 98/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.5026e-04 - mean_absolute_error: 0.0247\n",
            "Epoch 00098: val_loss did not improve from 0.00059\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.4922e-04 - mean_absolute_error: 0.0246 - val_loss: 6.3592e-04 - val_mean_absolute_error: 0.0225\n",
            "Epoch 99/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 6.5667e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 00099: val_loss improved from 0.00059 to 0.00058, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.5600e-04 - mean_absolute_error: 0.0245 - val_loss: 5.8477e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 100/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 6.4005e-04 - mean_absolute_error: 0.0243\n",
            "Epoch 00100: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.3950e-04 - mean_absolute_error: 0.0243 - val_loss: 6.7962e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 101/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 6.6622e-04 - mean_absolute_error: 0.0248\n",
            "Epoch 00101: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.6620e-04 - mean_absolute_error: 0.0248 - val_loss: 7.1075e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 102/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.5177e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00102: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.5177e-04 - mean_absolute_error: 0.0244 - val_loss: 5.9010e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 103/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.4855e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00103: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.4764e-04 - mean_absolute_error: 0.0244 - val_loss: 6.4195e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 104/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 6.5425e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 00104: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.5591e-04 - mean_absolute_error: 0.0245 - val_loss: 9.0856e-04 - val_mean_absolute_error: 0.0253\n",
            "Epoch 105/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.4307e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 00105: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.4262e-04 - mean_absolute_error: 0.0245 - val_loss: 6.0986e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 106/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 6.3834e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 00106: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.4110e-04 - mean_absolute_error: 0.0246 - val_loss: 6.2413e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 107/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.5326e-04 - mean_absolute_error: 0.0244\n",
            "Epoch 00107: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.5281e-04 - mean_absolute_error: 0.0244 - val_loss: 5.8616e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 108/400\n",
            "435/442 [============================>.] - ETA: 0s - loss: 6.3977e-04 - mean_absolute_error: 0.0245\n",
            "Epoch 00108: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.3637e-04 - mean_absolute_error: 0.0244 - val_loss: 6.2092e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 109/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.3582e-04 - mean_absolute_error: 0.0243\n",
            "Epoch 00109: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.3582e-04 - mean_absolute_error: 0.0243 - val_loss: 7.0482e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 110/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.1377e-04 - mean_absolute_error: 0.0241\n",
            "Epoch 00110: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.1295e-04 - mean_absolute_error: 0.0241 - val_loss: 6.0953e-04 - val_mean_absolute_error: 0.0207\n",
            "Epoch 111/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.3795e-04 - mean_absolute_error: 0.0242\n",
            "Epoch 00111: val_loss improved from 0.00058 to 0.00058, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.3785e-04 - mean_absolute_error: 0.0242 - val_loss: 5.8014e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 112/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.0709e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00112: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.1214e-04 - mean_absolute_error: 0.0239 - val_loss: 6.4749e-04 - val_mean_absolute_error: 0.0220\n",
            "Epoch 113/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 6.2844e-04 - mean_absolute_error: 0.0242\n",
            "Epoch 00113: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.2874e-04 - mean_absolute_error: 0.0242 - val_loss: 7.6285e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 114/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.2900e-04 - mean_absolute_error: 0.0241\n",
            "Epoch 00114: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.2832e-04 - mean_absolute_error: 0.0241 - val_loss: 8.3980e-04 - val_mean_absolute_error: 0.0243\n",
            "Epoch 115/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.1716e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00115: val_loss improved from 0.00058 to 0.00058, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.1663e-04 - mean_absolute_error: 0.0238 - val_loss: 5.7822e-04 - val_mean_absolute_error: 0.0208\n",
            "Epoch 116/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.1829e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00116: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.1829e-04 - mean_absolute_error: 0.0238 - val_loss: 6.5698e-04 - val_mean_absolute_error: 0.0236\n",
            "Epoch 117/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.3382e-04 - mean_absolute_error: 0.0241\n",
            "Epoch 00117: val_loss improved from 0.00058 to 0.00058, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.3268e-04 - mean_absolute_error: 0.0241 - val_loss: 5.7582e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 118/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 6.2779e-04 - mean_absolute_error: 0.0243\n",
            "Epoch 00118: val_loss did not improve from 0.00058\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.2993e-04 - mean_absolute_error: 0.0244 - val_loss: 6.1467e-04 - val_mean_absolute_error: 0.0232\n",
            "Epoch 119/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.0359e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00119: val_loss improved from 0.00058 to 0.00057, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.0359e-04 - mean_absolute_error: 0.0238 - val_loss: 5.6512e-04 - val_mean_absolute_error: 0.0232\n",
            "Epoch 120/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 6.1560e-04 - mean_absolute_error: 0.0239\n",
            "Epoch 00120: val_loss improved from 0.00057 to 0.00056, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.1669e-04 - mean_absolute_error: 0.0239 - val_loss: 5.6188e-04 - val_mean_absolute_error: 0.0205\n",
            "Epoch 121/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 6.0974e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00121: val_loss did not improve from 0.00056\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.0838e-04 - mean_absolute_error: 0.0237 - val_loss: 6.1982e-04 - val_mean_absolute_error: 0.0250\n",
            "Epoch 122/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.0414e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00122: val_loss improved from 0.00056 to 0.00054, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.0398e-04 - mean_absolute_error: 0.0237 - val_loss: 5.4073e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 123/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.0656e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00123: val_loss did not improve from 0.00054\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.0584e-04 - mean_absolute_error: 0.0238 - val_loss: 5.7303e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 124/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.9932e-04 - mean_absolute_error: 0.0238\n",
            "Epoch 00124: val_loss did not improve from 0.00054\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.9721e-04 - mean_absolute_error: 0.0237 - val_loss: 5.7563e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 125/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 6.0730e-04 - mean_absolute_error: 0.0236\n",
            "Epoch 00125: val_loss did not improve from 0.00054\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.0730e-04 - mean_absolute_error: 0.0236 - val_loss: 6.1147e-04 - val_mean_absolute_error: 0.0223\n",
            "Epoch 126/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 5.9554e-04 - mean_absolute_error: 0.0235\n",
            "Epoch 00126: val_loss did not improve from 0.00054\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.9525e-04 - mean_absolute_error: 0.0235 - val_loss: 5.9910e-04 - val_mean_absolute_error: 0.0212\n",
            "Epoch 127/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.8714e-04 - mean_absolute_error: 0.0234\n",
            "Epoch 00127: val_loss improved from 0.00054 to 0.00050, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.8704e-04 - mean_absolute_error: 0.0234 - val_loss: 5.0049e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 128/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 6.3052e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00128: val_loss did not improve from 0.00050\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 6.3003e-04 - mean_absolute_error: 0.0237 - val_loss: 6.5679e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 129/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.9904e-04 - mean_absolute_error: 0.0236\n",
            "Epoch 00129: val_loss did not improve from 0.00050\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.9904e-04 - mean_absolute_error: 0.0236 - val_loss: 9.2542e-04 - val_mean_absolute_error: 0.0243\n",
            "Epoch 130/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.7747e-04 - mean_absolute_error: 0.0232\n",
            "Epoch 00130: val_loss did not improve from 0.00050\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.7683e-04 - mean_absolute_error: 0.0232 - val_loss: 5.5027e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 131/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.9894e-04 - mean_absolute_error: 0.0237\n",
            "Epoch 00131: val_loss did not improve from 0.00050\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.9894e-04 - mean_absolute_error: 0.0237 - val_loss: 6.1194e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 132/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.8983e-04 - mean_absolute_error: 0.0234\n",
            "Epoch 00132: val_loss did not improve from 0.00050\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.8827e-04 - mean_absolute_error: 0.0233 - val_loss: 5.4675e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 133/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.9729e-04 - mean_absolute_error: 0.0234\n",
            "Epoch 00133: val_loss did not improve from 0.00050\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.9714e-04 - mean_absolute_error: 0.0233 - val_loss: 6.5712e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 134/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.9113e-04 - mean_absolute_error: 0.0232\n",
            "Epoch 00134: val_loss did not improve from 0.00050\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.8953e-04 - mean_absolute_error: 0.0232 - val_loss: 6.4577e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 135/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.9660e-04 - mean_absolute_error: 0.0236\n",
            "Epoch 00135: val_loss improved from 0.00050 to 0.00049, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.9484e-04 - mean_absolute_error: 0.0235 - val_loss: 4.9215e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 136/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 6.1708e-04 - mean_absolute_error: 0.0236\n",
            "Epoch 00136: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 6.1591e-04 - mean_absolute_error: 0.0236 - val_loss: 5.2284e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 137/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.6523e-04 - mean_absolute_error: 0.0230\n",
            "Epoch 00137: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.6508e-04 - mean_absolute_error: 0.0230 - val_loss: 5.0021e-04 - val_mean_absolute_error: 0.0213\n",
            "Epoch 138/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 5.6804e-04 - mean_absolute_error: 0.0232\n",
            "Epoch 00138: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.7122e-04 - mean_absolute_error: 0.0232 - val_loss: 4.9931e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 139/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.6969e-04 - mean_absolute_error: 0.0230\n",
            "Epoch 00139: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.6969e-04 - mean_absolute_error: 0.0230 - val_loss: 6.1723e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 140/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.6951e-04 - mean_absolute_error: 0.0229\n",
            "Epoch 00140: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.6812e-04 - mean_absolute_error: 0.0229 - val_loss: 5.5616e-04 - val_mean_absolute_error: 0.0212\n",
            "Epoch 141/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.6626e-04 - mean_absolute_error: 0.0230\n",
            "Epoch 00141: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.6578e-04 - mean_absolute_error: 0.0230 - val_loss: 5.6008e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 142/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.8212e-04 - mean_absolute_error: 0.0232\n",
            "Epoch 00142: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.8212e-04 - mean_absolute_error: 0.0232 - val_loss: 7.7307e-04 - val_mean_absolute_error: 0.0234\n",
            "Epoch 143/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.9106e-04 - mean_absolute_error: 0.0231\n",
            "Epoch 00143: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.9313e-04 - mean_absolute_error: 0.0232 - val_loss: 5.5594e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 144/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.7822e-04 - mean_absolute_error: 0.0229\n",
            "Epoch 00144: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.7750e-04 - mean_absolute_error: 0.0229 - val_loss: 5.2398e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 145/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.6570e-04 - mean_absolute_error: 0.0230\n",
            "Epoch 00145: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.6652e-04 - mean_absolute_error: 0.0230 - val_loss: 5.5485e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 146/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.6591e-04 - mean_absolute_error: 0.0228\n",
            "Epoch 00146: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.6583e-04 - mean_absolute_error: 0.0228 - val_loss: 6.3976e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 147/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.8644e-04 - mean_absolute_error: 0.0232\n",
            "Epoch 00147: val_loss improved from 0.00049 to 0.00049, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.8443e-04 - mean_absolute_error: 0.0232 - val_loss: 4.8830e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 148/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.6195e-04 - mean_absolute_error: 0.0226\n",
            "Epoch 00148: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.6214e-04 - mean_absolute_error: 0.0226 - val_loss: 5.5187e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 149/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.3947e-04 - mean_absolute_error: 0.0225\n",
            "Epoch 00149: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.3824e-04 - mean_absolute_error: 0.0225 - val_loss: 6.2032e-04 - val_mean_absolute_error: 0.0216\n",
            "Epoch 150/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.4821e-04 - mean_absolute_error: 0.0226\n",
            "Epoch 00150: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.4890e-04 - mean_absolute_error: 0.0226 - val_loss: 5.0637e-04 - val_mean_absolute_error: 0.0210\n",
            "Epoch 151/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.4565e-04 - mean_absolute_error: 0.0225\n",
            "Epoch 00151: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.4609e-04 - mean_absolute_error: 0.0226 - val_loss: 5.2886e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 152/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.3781e-04 - mean_absolute_error: 0.0223\n",
            "Epoch 00152: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.3489e-04 - mean_absolute_error: 0.0223 - val_loss: 6.2333e-04 - val_mean_absolute_error: 0.0208\n",
            "Epoch 153/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.8768e-04 - mean_absolute_error: 0.0228\n",
            "Epoch 00153: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.8719e-04 - mean_absolute_error: 0.0229 - val_loss: 5.8054e-04 - val_mean_absolute_error: 0.0226\n",
            "Epoch 154/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.6671e-04 - mean_absolute_error: 0.0228\n",
            "Epoch 00154: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.6431e-04 - mean_absolute_error: 0.0227 - val_loss: 6.0107e-04 - val_mean_absolute_error: 0.0217\n",
            "Epoch 155/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.3852e-04 - mean_absolute_error: 0.0223\n",
            "Epoch 00155: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.3852e-04 - mean_absolute_error: 0.0223 - val_loss: 5.1548e-04 - val_mean_absolute_error: 0.0199\n",
            "Epoch 156/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.2303e-04 - mean_absolute_error: 0.0221\n",
            "Epoch 00156: val_loss did not improve from 0.00049\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.2343e-04 - mean_absolute_error: 0.0221 - val_loss: 5.3231e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 157/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 5.3203e-04 - mean_absolute_error: 0.0221\n",
            "Epoch 00157: val_loss improved from 0.00049 to 0.00047, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.3378e-04 - mean_absolute_error: 0.0221 - val_loss: 4.6649e-04 - val_mean_absolute_error: 0.0193\n",
            "Epoch 158/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.3649e-04 - mean_absolute_error: 0.0223\n",
            "Epoch 00158: val_loss did not improve from 0.00047\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.3649e-04 - mean_absolute_error: 0.0223 - val_loss: 7.2315e-04 - val_mean_absolute_error: 0.0228\n",
            "Epoch 159/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 5.4147e-04 - mean_absolute_error: 0.0224\n",
            "Epoch 00159: val_loss did not improve from 0.00047\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.4124e-04 - mean_absolute_error: 0.0224 - val_loss: 5.2115e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 160/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.3519e-04 - mean_absolute_error: 0.0224\n",
            "Epoch 00160: val_loss did not improve from 0.00047\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.3397e-04 - mean_absolute_error: 0.0223 - val_loss: 5.3627e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 161/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.4471e-04 - mean_absolute_error: 0.0220\n",
            "Epoch 00161: val_loss did not improve from 0.00047\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.4400e-04 - mean_absolute_error: 0.0220 - val_loss: 4.9341e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 162/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.4171e-04 - mean_absolute_error: 0.0222\n",
            "Epoch 00162: val_loss did not improve from 0.00047\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.4036e-04 - mean_absolute_error: 0.0222 - val_loss: 5.0045e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 163/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.1386e-04 - mean_absolute_error: 0.0220\n",
            "Epoch 00163: val_loss improved from 0.00047 to 0.00045, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.1386e-04 - mean_absolute_error: 0.0220 - val_loss: 4.4543e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 164/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.2345e-04 - mean_absolute_error: 0.0220\n",
            "Epoch 00164: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.2345e-04 - mean_absolute_error: 0.0220 - val_loss: 5.0821e-04 - val_mean_absolute_error: 0.0203\n",
            "Epoch 165/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 5.2304e-04 - mean_absolute_error: 0.0219\n",
            "Epoch 00165: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.2328e-04 - mean_absolute_error: 0.0219 - val_loss: 5.3910e-04 - val_mean_absolute_error: 0.0199\n",
            "Epoch 166/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.4345e-04 - mean_absolute_error: 0.0222\n",
            "Epoch 00166: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.4435e-04 - mean_absolute_error: 0.0222 - val_loss: 4.7609e-04 - val_mean_absolute_error: 0.0189\n",
            "Epoch 167/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.2057e-04 - mean_absolute_error: 0.0219\n",
            "Epoch 00167: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.2337e-04 - mean_absolute_error: 0.0220 - val_loss: 7.0547e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 168/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.5747e-04 - mean_absolute_error: 0.0222\n",
            "Epoch 00168: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.5747e-04 - mean_absolute_error: 0.0222 - val_loss: 4.7467e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 169/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.3347e-04 - mean_absolute_error: 0.0221\n",
            "Epoch 00169: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.3478e-04 - mean_absolute_error: 0.0221 - val_loss: 4.7048e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 170/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.1087e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 00170: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.1047e-04 - mean_absolute_error: 0.0217 - val_loss: 5.3154e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 171/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.9253e-04 - mean_absolute_error: 0.0215\n",
            "Epoch 00171: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.9095e-04 - mean_absolute_error: 0.0215 - val_loss: 4.5799e-04 - val_mean_absolute_error: 0.0202\n",
            "Epoch 172/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.3737e-04 - mean_absolute_error: 0.0221\n",
            "Epoch 00172: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.4052e-04 - mean_absolute_error: 0.0221 - val_loss: 5.2956e-04 - val_mean_absolute_error: 0.0214\n",
            "Epoch 173/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.1224e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 00173: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.1224e-04 - mean_absolute_error: 0.0216 - val_loss: 4.6412e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 174/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.1817e-04 - mean_absolute_error: 0.0217\n",
            "Epoch 00174: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.1730e-04 - mean_absolute_error: 0.0217 - val_loss: 4.7171e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 175/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.0259e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 00175: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.0076e-04 - mean_absolute_error: 0.0216 - val_loss: 4.7755e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 176/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.3341e-04 - mean_absolute_error: 0.0219\n",
            "Epoch 00176: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.3255e-04 - mean_absolute_error: 0.0219 - val_loss: 6.3251e-04 - val_mean_absolute_error: 0.0218\n",
            "Epoch 177/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.1914e-04 - mean_absolute_error: 0.0217\n",
            "Epoch 00177: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.1690e-04 - mean_absolute_error: 0.0217 - val_loss: 4.6236e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 178/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 4.9063e-04 - mean_absolute_error: 0.0214\n",
            "Epoch 00178: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.9310e-04 - mean_absolute_error: 0.0214 - val_loss: 4.7237e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 179/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 4.9691e-04 - mean_absolute_error: 0.0214\n",
            "Epoch 00179: val_loss did not improve from 0.00045\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.9691e-04 - mean_absolute_error: 0.0214 - val_loss: 4.9753e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 180/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.1297e-04 - mean_absolute_error: 0.0218\n",
            "Epoch 00180: val_loss improved from 0.00045 to 0.00042, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.1188e-04 - mean_absolute_error: 0.0218 - val_loss: 4.2410e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 181/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 4.9583e-04 - mean_absolute_error: 0.0215\n",
            "Epoch 00181: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.9454e-04 - mean_absolute_error: 0.0214 - val_loss: 5.1081e-04 - val_mean_absolute_error: 0.0207\n",
            "Epoch 182/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.2145e-04 - mean_absolute_error: 0.0217\n",
            "Epoch 00182: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.2310e-04 - mean_absolute_error: 0.0217 - val_loss: 4.9607e-04 - val_mean_absolute_error: 0.0206\n",
            "Epoch 183/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.1721e-04 - mean_absolute_error: 0.0217\n",
            "Epoch 00183: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.1685e-04 - mean_absolute_error: 0.0217 - val_loss: 4.5649e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 184/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.9517e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 00184: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.9619e-04 - mean_absolute_error: 0.0217 - val_loss: 4.5939e-04 - val_mean_absolute_error: 0.0200\n",
            "Epoch 185/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.9820e-04 - mean_absolute_error: 0.0213\n",
            "Epoch 00185: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.9800e-04 - mean_absolute_error: 0.0213 - val_loss: 4.3918e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 186/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 5.0589e-04 - mean_absolute_error: 0.0215\n",
            "Epoch 00186: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.0479e-04 - mean_absolute_error: 0.0215 - val_loss: 4.6025e-04 - val_mean_absolute_error: 0.0193\n",
            "Epoch 187/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.0719e-04 - mean_absolute_error: 0.0216\n",
            "Epoch 00187: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.0555e-04 - mean_absolute_error: 0.0216 - val_loss: 4.3065e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 188/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.9018e-04 - mean_absolute_error: 0.0213\n",
            "Epoch 00188: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.8992e-04 - mean_absolute_error: 0.0213 - val_loss: 5.8519e-04 - val_mean_absolute_error: 0.0221\n",
            "Epoch 189/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 4.9026e-04 - mean_absolute_error: 0.0213\n",
            "Epoch 00189: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.9000e-04 - mean_absolute_error: 0.0213 - val_loss: 5.1415e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 190/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.1211e-04 - mean_absolute_error: 0.0213\n",
            "Epoch 00190: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.1095e-04 - mean_absolute_error: 0.0213 - val_loss: 4.4388e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 191/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 5.1399e-04 - mean_absolute_error: 0.0218\n",
            "Epoch 00191: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.1536e-04 - mean_absolute_error: 0.0218 - val_loss: 5.4556e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 192/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 5.2120e-04 - mean_absolute_error: 0.0217\n",
            "Epoch 00192: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.2120e-04 - mean_absolute_error: 0.0217 - val_loss: 4.7345e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 193/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 4.7420e-04 - mean_absolute_error: 0.0211\n",
            "Epoch 00193: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.7445e-04 - mean_absolute_error: 0.0211 - val_loss: 5.2343e-04 - val_mean_absolute_error: 0.0205\n",
            "Epoch 194/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 5.1468e-04 - mean_absolute_error: 0.0215\n",
            "Epoch 00194: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 5.1385e-04 - mean_absolute_error: 0.0215 - val_loss: 5.0074e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 195/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.8294e-04 - mean_absolute_error: 0.0212\n",
            "Epoch 00195: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.8476e-04 - mean_absolute_error: 0.0213 - val_loss: 4.7126e-04 - val_mean_absolute_error: 0.0201\n",
            "Epoch 196/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.7955e-04 - mean_absolute_error: 0.0209\n",
            "Epoch 00196: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.7888e-04 - mean_absolute_error: 0.0208 - val_loss: 4.3549e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 197/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 5.0846e-04 - mean_absolute_error: 0.0215\n",
            "Epoch 00197: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 5.0617e-04 - mean_absolute_error: 0.0214 - val_loss: 4.8396e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 198/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.8587e-04 - mean_absolute_error: 0.0210\n",
            "Epoch 00198: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.9035e-04 - mean_absolute_error: 0.0211 - val_loss: 4.8186e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 199/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.5927e-04 - mean_absolute_error: 0.0209\n",
            "Epoch 00199: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.6387e-04 - mean_absolute_error: 0.0210 - val_loss: 4.2700e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 200/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 4.8502e-04 - mean_absolute_error: 0.0212\n",
            "Epoch 00200: val_loss did not improve from 0.00042\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.8559e-04 - mean_absolute_error: 0.0212 - val_loss: 4.4394e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 201/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.7620e-04 - mean_absolute_error: 0.0210\n",
            "Epoch 00201: val_loss improved from 0.00042 to 0.00041, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.7651e-04 - mean_absolute_error: 0.0210 - val_loss: 4.1181e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 202/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.8229e-04 - mean_absolute_error: 0.0211\n",
            "Epoch 00202: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.8058e-04 - mean_absolute_error: 0.0210 - val_loss: 4.8140e-04 - val_mean_absolute_error: 0.0196\n",
            "Epoch 203/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.8026e-04 - mean_absolute_error: 0.0211\n",
            "Epoch 00203: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.7862e-04 - mean_absolute_error: 0.0211 - val_loss: 4.2878e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 204/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.7564e-04 - mean_absolute_error: 0.0208\n",
            "Epoch 00204: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.7494e-04 - mean_absolute_error: 0.0208 - val_loss: 5.1950e-04 - val_mean_absolute_error: 0.0197\n",
            "Epoch 205/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.7748e-04 - mean_absolute_error: 0.0209\n",
            "Epoch 00205: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.7692e-04 - mean_absolute_error: 0.0209 - val_loss: 4.9499e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 206/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 4.6879e-04 - mean_absolute_error: 0.0208\n",
            "Epoch 00206: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.6702e-04 - mean_absolute_error: 0.0207 - val_loss: 4.2712e-04 - val_mean_absolute_error: 0.0186\n",
            "Epoch 207/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.5659e-04 - mean_absolute_error: 0.0206\n",
            "Epoch 00207: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.5619e-04 - mean_absolute_error: 0.0206 - val_loss: 4.7202e-04 - val_mean_absolute_error: 0.0204\n",
            "Epoch 208/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 4.5451e-04 - mean_absolute_error: 0.0206\n",
            "Epoch 00208: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.5451e-04 - mean_absolute_error: 0.0206 - val_loss: 4.5198e-04 - val_mean_absolute_error: 0.0188\n",
            "Epoch 209/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.5563e-04 - mean_absolute_error: 0.0204\n",
            "Epoch 00209: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.5562e-04 - mean_absolute_error: 0.0204 - val_loss: 5.0243e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 210/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.8180e-04 - mean_absolute_error: 0.0210\n",
            "Epoch 00210: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.8118e-04 - mean_absolute_error: 0.0210 - val_loss: 4.2912e-04 - val_mean_absolute_error: 0.0186\n",
            "Epoch 211/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.4410e-04 - mean_absolute_error: 0.0203\n",
            "Epoch 00211: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4475e-04 - mean_absolute_error: 0.0203 - val_loss: 4.1961e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 212/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.5818e-04 - mean_absolute_error: 0.0205\n",
            "Epoch 00212: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.5887e-04 - mean_absolute_error: 0.0205 - val_loss: 4.9788e-04 - val_mean_absolute_error: 0.0188\n",
            "Epoch 213/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 4.6452e-04 - mean_absolute_error: 0.0206\n",
            "Epoch 00213: val_loss improved from 0.00041 to 0.00041, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.6452e-04 - mean_absolute_error: 0.0206 - val_loss: 4.0632e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 214/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 4.6054e-04 - mean_absolute_error: 0.0205\n",
            "Epoch 00214: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.6054e-04 - mean_absolute_error: 0.0205 - val_loss: 4.1131e-04 - val_mean_absolute_error: 0.0180\n",
            "Epoch 215/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.4099e-04 - mean_absolute_error: 0.0203\n",
            "Epoch 00215: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3970e-04 - mean_absolute_error: 0.0202 - val_loss: 4.3015e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 216/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.4599e-04 - mean_absolute_error: 0.0202\n",
            "Epoch 00216: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4724e-04 - mean_absolute_error: 0.0202 - val_loss: 4.2398e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 217/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.5819e-04 - mean_absolute_error: 0.0204\n",
            "Epoch 00217: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.5899e-04 - mean_absolute_error: 0.0204 - val_loss: 4.9426e-04 - val_mean_absolute_error: 0.0208\n",
            "Epoch 218/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.5678e-04 - mean_absolute_error: 0.0203\n",
            "Epoch 00218: val_loss did not improve from 0.00041\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.5683e-04 - mean_absolute_error: 0.0203 - val_loss: 5.8469e-04 - val_mean_absolute_error: 0.0211\n",
            "Epoch 219/400\n",
            "435/442 [============================>.] - ETA: 0s - loss: 4.4962e-04 - mean_absolute_error: 0.0204\n",
            "Epoch 00219: val_loss improved from 0.00041 to 0.00037, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4748e-04 - mean_absolute_error: 0.0204 - val_loss: 3.7019e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 220/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.3946e-04 - mean_absolute_error: 0.0203\n",
            "Epoch 00220: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4019e-04 - mean_absolute_error: 0.0203 - val_loss: 3.9783e-04 - val_mean_absolute_error: 0.0184\n",
            "Epoch 221/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.3901e-04 - mean_absolute_error: 0.0201\n",
            "Epoch 00221: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3759e-04 - mean_absolute_error: 0.0201 - val_loss: 3.7200e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 222/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 4.2496e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 00222: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.2496e-04 - mean_absolute_error: 0.0199 - val_loss: 3.9902e-04 - val_mean_absolute_error: 0.0178\n",
            "Epoch 223/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.5035e-04 - mean_absolute_error: 0.0204\n",
            "Epoch 00223: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4993e-04 - mean_absolute_error: 0.0204 - val_loss: 3.7559e-04 - val_mean_absolute_error: 0.0180\n",
            "Epoch 224/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.8913e-04 - mean_absolute_error: 0.0206\n",
            "Epoch 00224: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.8831e-04 - mean_absolute_error: 0.0206 - val_loss: 4.1999e-04 - val_mean_absolute_error: 0.0189\n",
            "Epoch 225/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.3349e-04 - mean_absolute_error: 0.0200\n",
            "Epoch 00225: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.3354e-04 - mean_absolute_error: 0.0200 - val_loss: 4.0457e-04 - val_mean_absolute_error: 0.0176\n",
            "Epoch 226/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.3127e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 00226: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3066e-04 - mean_absolute_error: 0.0199 - val_loss: 3.9461e-04 - val_mean_absolute_error: 0.0176\n",
            "Epoch 227/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 4.4149e-04 - mean_absolute_error: 0.0201\n",
            "Epoch 00227: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4232e-04 - mean_absolute_error: 0.0201 - val_loss: 3.9365e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 228/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.3310e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 00228: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3295e-04 - mean_absolute_error: 0.0199 - val_loss: 4.4094e-04 - val_mean_absolute_error: 0.0190\n",
            "Epoch 229/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 4.4772e-04 - mean_absolute_error: 0.0200\n",
            "Epoch 00229: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4638e-04 - mean_absolute_error: 0.0200 - val_loss: 3.7038e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 230/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.2247e-04 - mean_absolute_error: 0.0197\n",
            "Epoch 00230: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.2194e-04 - mean_absolute_error: 0.0197 - val_loss: 5.4174e-04 - val_mean_absolute_error: 0.0195\n",
            "Epoch 231/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.3896e-04 - mean_absolute_error: 0.0200\n",
            "Epoch 00231: val_loss did not improve from 0.00037\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3839e-04 - mean_absolute_error: 0.0200 - val_loss: 5.2512e-04 - val_mean_absolute_error: 0.0192\n",
            "Epoch 232/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.3154e-04 - mean_absolute_error: 0.0196\n",
            "Epoch 00232: val_loss improved from 0.00037 to 0.00035, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3099e-04 - mean_absolute_error: 0.0196 - val_loss: 3.4512e-04 - val_mean_absolute_error: 0.0165\n",
            "Epoch 233/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 4.5364e-04 - mean_absolute_error: 0.0199\n",
            "Epoch 00233: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.5364e-04 - mean_absolute_error: 0.0199 - val_loss: 4.1406e-04 - val_mean_absolute_error: 0.0193\n",
            "Epoch 234/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.1038e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 00234: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.1013e-04 - mean_absolute_error: 0.0195 - val_loss: 4.5443e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 235/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 4.0496e-04 - mean_absolute_error: 0.0193\n",
            "Epoch 00235: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.0440e-04 - mean_absolute_error: 0.0193 - val_loss: 3.9829e-04 - val_mean_absolute_error: 0.0176\n",
            "Epoch 236/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.2265e-04 - mean_absolute_error: 0.0194\n",
            "Epoch 00236: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.2217e-04 - mean_absolute_error: 0.0194 - val_loss: 3.5417e-04 - val_mean_absolute_error: 0.0165\n",
            "Epoch 237/400\n",
            "435/442 [============================>.] - ETA: 0s - loss: 4.2131e-04 - mean_absolute_error: 0.0196\n",
            "Epoch 00237: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.2043e-04 - mean_absolute_error: 0.0196 - val_loss: 4.1946e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 238/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.4816e-04 - mean_absolute_error: 0.0198\n",
            "Epoch 00238: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.4895e-04 - mean_absolute_error: 0.0198 - val_loss: 3.7534e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 239/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 4.4042e-04 - mean_absolute_error: 0.0198\n",
            "Epoch 00239: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3952e-04 - mean_absolute_error: 0.0197 - val_loss: 3.9329e-04 - val_mean_absolute_error: 0.0177\n",
            "Epoch 240/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 4.3184e-04 - mean_absolute_error: 0.0198\n",
            "Epoch 00240: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.3094e-04 - mean_absolute_error: 0.0198 - val_loss: 4.9806e-04 - val_mean_absolute_error: 0.0191\n",
            "Epoch 241/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.2082e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 00241: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 4.2177e-04 - mean_absolute_error: 0.0196 - val_loss: 3.5762e-04 - val_mean_absolute_error: 0.0165\n",
            "Epoch 242/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.1811e-04 - mean_absolute_error: 0.0194\n",
            "Epoch 00242: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.1727e-04 - mean_absolute_error: 0.0194 - val_loss: 5.6268e-04 - val_mean_absolute_error: 0.0198\n",
            "Epoch 243/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 4.0715e-04 - mean_absolute_error: 0.0194\n",
            "Epoch 00243: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.0641e-04 - mean_absolute_error: 0.0194 - val_loss: 3.9781e-04 - val_mean_absolute_error: 0.0176\n",
            "Epoch 244/400\n",
            "435/442 [============================>.] - ETA: 0s - loss: 4.0294e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 00244: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.0232e-04 - mean_absolute_error: 0.0192 - val_loss: 4.5374e-04 - val_mean_absolute_error: 0.0186\n",
            "Epoch 245/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.9137e-04 - mean_absolute_error: 0.0188\n",
            "Epoch 00245: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.8995e-04 - mean_absolute_error: 0.0187 - val_loss: 5.2023e-04 - val_mean_absolute_error: 0.0184\n",
            "Epoch 246/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.1174e-04 - mean_absolute_error: 0.0192\n",
            "Epoch 00246: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.1155e-04 - mean_absolute_error: 0.0192 - val_loss: 3.5559e-04 - val_mean_absolute_error: 0.0167\n",
            "Epoch 247/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.9306e-04 - mean_absolute_error: 0.0189\n",
            "Epoch 00247: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.9306e-04 - mean_absolute_error: 0.0189 - val_loss: 4.2118e-04 - val_mean_absolute_error: 0.0187\n",
            "Epoch 248/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.9824e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 00248: val_loss did not improve from 0.00035\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.9780e-04 - mean_absolute_error: 0.0190 - val_loss: 3.5480e-04 - val_mean_absolute_error: 0.0164\n",
            "Epoch 249/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.9033e-04 - mean_absolute_error: 0.0189\n",
            "Epoch 00249: val_loss improved from 0.00035 to 0.00033, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.8928e-04 - mean_absolute_error: 0.0189 - val_loss: 3.2946e-04 - val_mean_absolute_error: 0.0159\n",
            "Epoch 250/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.9377e-04 - mean_absolute_error: 0.0189\n",
            "Epoch 00250: val_loss improved from 0.00033 to 0.00032, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.9377e-04 - mean_absolute_error: 0.0189 - val_loss: 3.2261e-04 - val_mean_absolute_error: 0.0169\n",
            "Epoch 251/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 4.0145e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 00251: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.0262e-04 - mean_absolute_error: 0.0190 - val_loss: 4.2912e-04 - val_mean_absolute_error: 0.0174\n",
            "Epoch 252/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 4.1095e-04 - mean_absolute_error: 0.0190\n",
            "Epoch 00252: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 4.0837e-04 - mean_absolute_error: 0.0189 - val_loss: 4.0760e-04 - val_mean_absolute_error: 0.0179\n",
            "Epoch 253/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.9132e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 00253: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.9098e-04 - mean_absolute_error: 0.0187 - val_loss: 3.5631e-04 - val_mean_absolute_error: 0.0166\n",
            "Epoch 254/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.7708e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 00254: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.7614e-04 - mean_absolute_error: 0.0187 - val_loss: 4.4580e-04 - val_mean_absolute_error: 0.0174\n",
            "Epoch 255/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.7540e-04 - mean_absolute_error: 0.0186\n",
            "Epoch 00255: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.7571e-04 - mean_absolute_error: 0.0186 - val_loss: 3.4853e-04 - val_mean_absolute_error: 0.0177\n",
            "Epoch 256/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.7774e-04 - mean_absolute_error: 0.0185\n",
            "Epoch 00256: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.7957e-04 - mean_absolute_error: 0.0186 - val_loss: 3.5266e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 257/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.9231e-04 - mean_absolute_error: 0.0189\n",
            "Epoch 00257: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.9414e-04 - mean_absolute_error: 0.0189 - val_loss: 3.6721e-04 - val_mean_absolute_error: 0.0163\n",
            "Epoch 258/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.7880e-04 - mean_absolute_error: 0.0184\n",
            "Epoch 00258: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7880e-04 - mean_absolute_error: 0.0184 - val_loss: 4.8963e-04 - val_mean_absolute_error: 0.0175\n",
            "Epoch 259/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.8379e-04 - mean_absolute_error: 0.0185\n",
            "Epoch 00259: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.8333e-04 - mean_absolute_error: 0.0185 - val_loss: 3.3386e-04 - val_mean_absolute_error: 0.0159\n",
            "Epoch 260/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.7904e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 00260: val_loss improved from 0.00032 to 0.00032, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7646e-04 - mean_absolute_error: 0.0182 - val_loss: 3.1880e-04 - val_mean_absolute_error: 0.0159\n",
            "Epoch 261/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.8124e-04 - mean_absolute_error: 0.0186\n",
            "Epoch 00261: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.8117e-04 - mean_absolute_error: 0.0186 - val_loss: 3.9826e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 262/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.7578e-04 - mean_absolute_error: 0.0185\n",
            "Epoch 00262: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7637e-04 - mean_absolute_error: 0.0185 - val_loss: 6.6454e-04 - val_mean_absolute_error: 0.0215\n",
            "Epoch 263/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.9387e-04 - mean_absolute_error: 0.0186\n",
            "Epoch 00263: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.9527e-04 - mean_absolute_error: 0.0186 - val_loss: 3.7388e-04 - val_mean_absolute_error: 0.0166\n",
            "Epoch 264/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.6609e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 00264: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.6541e-04 - mean_absolute_error: 0.0180 - val_loss: 3.2593e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 265/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.7113e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 00265: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7112e-04 - mean_absolute_error: 0.0182 - val_loss: 3.3069e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 266/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.6705e-04 - mean_absolute_error: 0.0181\n",
            "Epoch 00266: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.6970e-04 - mean_absolute_error: 0.0181 - val_loss: 3.4102e-04 - val_mean_absolute_error: 0.0170\n",
            "Epoch 267/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.8024e-04 - mean_absolute_error: 0.0181\n",
            "Epoch 00267: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.8024e-04 - mean_absolute_error: 0.0181 - val_loss: 3.2027e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 268/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.6015e-04 - mean_absolute_error: 0.0178\n",
            "Epoch 00268: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.5912e-04 - mean_absolute_error: 0.0178 - val_loss: 5.0152e-04 - val_mean_absolute_error: 0.0181\n",
            "Epoch 269/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.6176e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 00269: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.6109e-04 - mean_absolute_error: 0.0180 - val_loss: 4.4609e-04 - val_mean_absolute_error: 0.0172\n",
            "Epoch 270/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.4695e-04 - mean_absolute_error: 0.0176\n",
            "Epoch 00270: val_loss did not improve from 0.00032\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.4794e-04 - mean_absolute_error: 0.0176 - val_loss: 3.4749e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 271/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.7677e-04 - mean_absolute_error: 0.0182\n",
            "Epoch 00271: val_loss improved from 0.00032 to 0.00031, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7616e-04 - mean_absolute_error: 0.0182 - val_loss: 3.1354e-04 - val_mean_absolute_error: 0.0151\n",
            "Epoch 272/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 3.7118e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 00272: val_loss did not improve from 0.00031\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7140e-04 - mean_absolute_error: 0.0180 - val_loss: 3.2004e-04 - val_mean_absolute_error: 0.0153\n",
            "Epoch 273/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.7659e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 00273: val_loss did not improve from 0.00031\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7659e-04 - mean_absolute_error: 0.0180 - val_loss: 3.4318e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 274/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.5605e-04 - mean_absolute_error: 0.0177\n",
            "Epoch 00274: val_loss did not improve from 0.00031\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.5632e-04 - mean_absolute_error: 0.0177 - val_loss: 3.1425e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 275/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.7540e-04 - mean_absolute_error: 0.0181\n",
            "Epoch 00275: val_loss did not improve from 0.00031\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7719e-04 - mean_absolute_error: 0.0181 - val_loss: 3.8956e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 276/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.4703e-04 - mean_absolute_error: 0.0176\n",
            "Epoch 00276: val_loss did not improve from 0.00031\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.4641e-04 - mean_absolute_error: 0.0176 - val_loss: 3.2448e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 277/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.5914e-04 - mean_absolute_error: 0.0178\n",
            "Epoch 00277: val_loss did not improve from 0.00031\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.5873e-04 - mean_absolute_error: 0.0178 - val_loss: 3.3357e-04 - val_mean_absolute_error: 0.0162\n",
            "Epoch 278/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.4655e-04 - mean_absolute_error: 0.0174\n",
            "Epoch 00278: val_loss did not improve from 0.00031\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.4612e-04 - mean_absolute_error: 0.0174 - val_loss: 3.8203e-04 - val_mean_absolute_error: 0.0165\n",
            "Epoch 279/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.7641e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 00279: val_loss improved from 0.00031 to 0.00030, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7641e-04 - mean_absolute_error: 0.0180 - val_loss: 2.9925e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 280/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.5265e-04 - mean_absolute_error: 0.0177\n",
            "Epoch 00280: val_loss did not improve from 0.00030\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.5339e-04 - mean_absolute_error: 0.0177 - val_loss: 3.3252e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 281/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.5839e-04 - mean_absolute_error: 0.0176\n",
            "Epoch 00281: val_loss did not improve from 0.00030\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.5878e-04 - mean_absolute_error: 0.0177 - val_loss: 2.9966e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 282/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.5245e-04 - mean_absolute_error: 0.0176\n",
            "Epoch 00282: val_loss did not improve from 0.00030\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.5122e-04 - mean_absolute_error: 0.0176 - val_loss: 3.2456e-04 - val_mean_absolute_error: 0.0150\n",
            "Epoch 283/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.3935e-04 - mean_absolute_error: 0.0172\n",
            "Epoch 00283: val_loss did not improve from 0.00030\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.3935e-04 - mean_absolute_error: 0.0172 - val_loss: 3.0277e-04 - val_mean_absolute_error: 0.0156\n",
            "Epoch 284/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.2877e-04 - mean_absolute_error: 0.0172\n",
            "Epoch 00284: val_loss did not improve from 0.00030\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2961e-04 - mean_absolute_error: 0.0172 - val_loss: 3.0355e-04 - val_mean_absolute_error: 0.0149\n",
            "Epoch 285/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.7476e-04 - mean_absolute_error: 0.0178\n",
            "Epoch 00285: val_loss did not improve from 0.00030\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.7517e-04 - mean_absolute_error: 0.0178 - val_loss: 3.0067e-04 - val_mean_absolute_error: 0.0164\n",
            "Epoch 286/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.3207e-04 - mean_absolute_error: 0.0172\n",
            "Epoch 00286: val_loss did not improve from 0.00030\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.3261e-04 - mean_absolute_error: 0.0172 - val_loss: 3.6290e-04 - val_mean_absolute_error: 0.0153\n",
            "Epoch 287/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.4400e-04 - mean_absolute_error: 0.0174\n",
            "Epoch 00287: val_loss improved from 0.00030 to 0.00026, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.4400e-04 - mean_absolute_error: 0.0174 - val_loss: 2.6251e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 288/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.4780e-04 - mean_absolute_error: 0.0173\n",
            "Epoch 00288: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.4634e-04 - mean_absolute_error: 0.0173 - val_loss: 3.3049e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 289/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.2657e-04 - mean_absolute_error: 0.0170\n",
            "Epoch 00289: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.2653e-04 - mean_absolute_error: 0.0170 - val_loss: 2.9512e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 290/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.3701e-04 - mean_absolute_error: 0.0173\n",
            "Epoch 00290: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.3665e-04 - mean_absolute_error: 0.0172 - val_loss: 3.0766e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 291/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.5714e-04 - mean_absolute_error: 0.0174\n",
            "Epoch 00291: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.5633e-04 - mean_absolute_error: 0.0174 - val_loss: 2.7175e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 292/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.2448e-04 - mean_absolute_error: 0.0168\n",
            "Epoch 00292: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2493e-04 - mean_absolute_error: 0.0168 - val_loss: 2.6384e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 293/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.2191e-04 - mean_absolute_error: 0.0169\n",
            "Epoch 00293: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2202e-04 - mean_absolute_error: 0.0169 - val_loss: 3.0013e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 294/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.3707e-04 - mean_absolute_error: 0.0172\n",
            "Epoch 00294: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.3663e-04 - mean_absolute_error: 0.0172 - val_loss: 3.5439e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 295/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.3223e-04 - mean_absolute_error: 0.0169\n",
            "Epoch 00295: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.3247e-04 - mean_absolute_error: 0.0169 - val_loss: 2.7143e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 296/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.5372e-04 - mean_absolute_error: 0.0173\n",
            "Epoch 00296: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.5297e-04 - mean_absolute_error: 0.0173 - val_loss: 3.1048e-04 - val_mean_absolute_error: 0.0146\n",
            "Epoch 297/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 3.3017e-04 - mean_absolute_error: 0.0170\n",
            "Epoch 00297: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.2860e-04 - mean_absolute_error: 0.0170 - val_loss: 2.6265e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 298/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 3.2112e-04 - mean_absolute_error: 0.0168\n",
            "Epoch 00298: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2111e-04 - mean_absolute_error: 0.0168 - val_loss: 2.8000e-04 - val_mean_absolute_error: 0.0141\n",
            "Epoch 299/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.2134e-04 - mean_absolute_error: 0.0168\n",
            "Epoch 00299: val_loss did not improve from 0.00026\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2147e-04 - mean_absolute_error: 0.0168 - val_loss: 3.0174e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 300/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.1730e-04 - mean_absolute_error: 0.0168\n",
            "Epoch 00300: val_loss improved from 0.00026 to 0.00024, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.1652e-04 - mean_absolute_error: 0.0168 - val_loss: 2.3914e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 301/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.1888e-04 - mean_absolute_error: 0.0167\n",
            "Epoch 00301: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.1888e-04 - mean_absolute_error: 0.0167 - val_loss: 4.9812e-04 - val_mean_absolute_error: 0.0183\n",
            "Epoch 302/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.1499e-04 - mean_absolute_error: 0.0164\n",
            "Epoch 00302: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.1499e-04 - mean_absolute_error: 0.0164 - val_loss: 2.9856e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 303/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.1496e-04 - mean_absolute_error: 0.0167\n",
            "Epoch 00303: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.1541e-04 - mean_absolute_error: 0.0167 - val_loss: 2.7277e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 304/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.3196e-04 - mean_absolute_error: 0.0169\n",
            "Epoch 00304: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.3258e-04 - mean_absolute_error: 0.0169 - val_loss: 3.1966e-04 - val_mean_absolute_error: 0.0152\n",
            "Epoch 305/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 3.2278e-04 - mean_absolute_error: 0.0167\n",
            "Epoch 00305: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2184e-04 - mean_absolute_error: 0.0167 - val_loss: 3.6245e-04 - val_mean_absolute_error: 0.0148\n",
            "Epoch 306/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 3.0699e-04 - mean_absolute_error: 0.0163\n",
            "Epoch 00306: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.0680e-04 - mean_absolute_error: 0.0163 - val_loss: 2.8377e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 307/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.1206e-04 - mean_absolute_error: 0.0166\n",
            "Epoch 00307: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.1303e-04 - mean_absolute_error: 0.0166 - val_loss: 4.2570e-04 - val_mean_absolute_error: 0.0160\n",
            "Epoch 308/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.9307e-04 - mean_absolute_error: 0.0162\n",
            "Epoch 00308: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.9304e-04 - mean_absolute_error: 0.0162 - val_loss: 2.6773e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 309/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.0115e-04 - mean_absolute_error: 0.0160\n",
            "Epoch 00309: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.0115e-04 - mean_absolute_error: 0.0160 - val_loss: 2.5483e-04 - val_mean_absolute_error: 0.0137\n",
            "Epoch 310/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 3.2872e-04 - mean_absolute_error: 0.0166\n",
            "Epoch 00310: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2777e-04 - mean_absolute_error: 0.0165 - val_loss: 2.5284e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 311/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.9855e-04 - mean_absolute_error: 0.0160\n",
            "Epoch 00311: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.0351e-04 - mean_absolute_error: 0.0161 - val_loss: 2.8397e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 312/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 3.0226e-04 - mean_absolute_error: 0.0161\n",
            "Epoch 00312: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.0205e-04 - mean_absolute_error: 0.0161 - val_loss: 3.1788e-04 - val_mean_absolute_error: 0.0145\n",
            "Epoch 313/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.9690e-04 - mean_absolute_error: 0.0161\n",
            "Epoch 00313: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.9643e-04 - mean_absolute_error: 0.0161 - val_loss: 2.7643e-04 - val_mean_absolute_error: 0.0137\n",
            "Epoch 314/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 3.2256e-04 - mean_absolute_error: 0.0165\n",
            "Epoch 00314: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 3.2245e-04 - mean_absolute_error: 0.0165 - val_loss: 2.5130e-04 - val_mean_absolute_error: 0.0137\n",
            "Epoch 315/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.9605e-04 - mean_absolute_error: 0.0159\n",
            "Epoch 00315: val_loss improved from 0.00024 to 0.00024, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.9605e-04 - mean_absolute_error: 0.0159 - val_loss: 2.3739e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 316/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.8225e-04 - mean_absolute_error: 0.0157\n",
            "Epoch 00316: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.8225e-04 - mean_absolute_error: 0.0157 - val_loss: 2.6645e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 317/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.9390e-04 - mean_absolute_error: 0.0160\n",
            "Epoch 00317: val_loss improved from 0.00024 to 0.00024, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.9523e-04 - mean_absolute_error: 0.0160 - val_loss: 2.3553e-04 - val_mean_absolute_error: 0.0136\n",
            "Epoch 318/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.9158e-04 - mean_absolute_error: 0.0159\n",
            "Epoch 00318: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.9110e-04 - mean_absolute_error: 0.0159 - val_loss: 2.6274e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 319/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.7515e-04 - mean_absolute_error: 0.0156\n",
            "Epoch 00319: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.7488e-04 - mean_absolute_error: 0.0156 - val_loss: 2.3844e-04 - val_mean_absolute_error: 0.0140\n",
            "Epoch 320/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.9865e-04 - mean_absolute_error: 0.0161\n",
            "Epoch 00320: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.9972e-04 - mean_absolute_error: 0.0161 - val_loss: 3.3572e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 321/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.8840e-04 - mean_absolute_error: 0.0159\n",
            "Epoch 00321: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.8840e-04 - mean_absolute_error: 0.0159 - val_loss: 2.5389e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 322/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.9604e-04 - mean_absolute_error: 0.0160\n",
            "Epoch 00322: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.9589e-04 - mean_absolute_error: 0.0159 - val_loss: 2.4179e-04 - val_mean_absolute_error: 0.0130\n",
            "Epoch 323/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.6908e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00323: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.6892e-04 - mean_absolute_error: 0.0154 - val_loss: 2.3677e-04 - val_mean_absolute_error: 0.0127\n",
            "Epoch 324/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.7670e-04 - mean_absolute_error: 0.0156\n",
            "Epoch 00324: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.7615e-04 - mean_absolute_error: 0.0156 - val_loss: 2.4305e-04 - val_mean_absolute_error: 0.0129\n",
            "Epoch 325/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 2.8350e-04 - mean_absolute_error: 0.0156\n",
            "Epoch 00325: val_loss did not improve from 0.00024\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.8281e-04 - mean_absolute_error: 0.0156 - val_loss: 3.5042e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 326/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.8202e-04 - mean_absolute_error: 0.0157\n",
            "Epoch 00326: val_loss improved from 0.00024 to 0.00022, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.8222e-04 - mean_absolute_error: 0.0157 - val_loss: 2.2418e-04 - val_mean_absolute_error: 0.0135\n",
            "Epoch 327/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.6446e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00327: val_loss did not improve from 0.00022\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.6491e-04 - mean_absolute_error: 0.0153 - val_loss: 2.3801e-04 - val_mean_absolute_error: 0.0130\n",
            "Epoch 328/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.7255e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00328: val_loss did not improve from 0.00022\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.7262e-04 - mean_absolute_error: 0.0154 - val_loss: 3.3347e-04 - val_mean_absolute_error: 0.0153\n",
            "Epoch 329/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.6428e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00329: val_loss did not improve from 0.00022\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.6428e-04 - mean_absolute_error: 0.0153 - val_loss: 2.3986e-04 - val_mean_absolute_error: 0.0127\n",
            "Epoch 330/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.6367e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00330: val_loss did not improve from 0.00022\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.6356e-04 - mean_absolute_error: 0.0153 - val_loss: 3.4540e-04 - val_mean_absolute_error: 0.0157\n",
            "Epoch 331/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.6578e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00331: val_loss did not improve from 0.00022\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.6741e-04 - mean_absolute_error: 0.0153 - val_loss: 2.4931e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 332/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 2.8368e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00332: val_loss did not improve from 0.00022\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.8704e-04 - mean_absolute_error: 0.0154 - val_loss: 4.6344e-04 - val_mean_absolute_error: 0.0158\n",
            "Epoch 333/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.8204e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00333: val_loss improved from 0.00022 to 0.00021, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.8170e-04 - mean_absolute_error: 0.0154 - val_loss: 2.1147e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 334/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.7094e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00334: val_loss improved from 0.00021 to 0.00020, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.7155e-04 - mean_absolute_error: 0.0153 - val_loss: 2.0429e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 335/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.7298e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00335: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.7178e-04 - mean_absolute_error: 0.0153 - val_loss: 2.3709e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 336/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.6414e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 00336: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.6421e-04 - mean_absolute_error: 0.0152 - val_loss: 2.0884e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 337/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 3.0044e-04 - mean_absolute_error: 0.0157\n",
            "Epoch 00337: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 3.0044e-04 - mean_absolute_error: 0.0157 - val_loss: 2.0832e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 338/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 2.6218e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 00338: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.6167e-04 - mean_absolute_error: 0.0151 - val_loss: 2.5801e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 339/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.7199e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 00339: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.7166e-04 - mean_absolute_error: 0.0152 - val_loss: 2.2184e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 340/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.5723e-04 - mean_absolute_error: 0.0150\n",
            "Epoch 00340: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.5670e-04 - mean_absolute_error: 0.0150 - val_loss: 2.0932e-04 - val_mean_absolute_error: 0.0123\n",
            "Epoch 341/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.4948e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 00341: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.4881e-04 - mean_absolute_error: 0.0146 - val_loss: 2.1670e-04 - val_mean_absolute_error: 0.0119\n",
            "Epoch 342/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.5254e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 00342: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.5275e-04 - mean_absolute_error: 0.0147 - val_loss: 2.0449e-04 - val_mean_absolute_error: 0.0120\n",
            "Epoch 343/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.5937e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 00343: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.5996e-04 - mean_absolute_error: 0.0151 - val_loss: 2.2878e-04 - val_mean_absolute_error: 0.0129\n",
            "Epoch 344/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.7694e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00344: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.7654e-04 - mean_absolute_error: 0.0154 - val_loss: 2.3692e-04 - val_mean_absolute_error: 0.0127\n",
            "Epoch 345/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.7049e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 00345: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.6997e-04 - mean_absolute_error: 0.0151 - val_loss: 3.0854e-04 - val_mean_absolute_error: 0.0155\n",
            "Epoch 346/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.6185e-04 - mean_absolute_error: 0.0148\n",
            "Epoch 00346: val_loss improved from 0.00020 to 0.00020, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.6179e-04 - mean_absolute_error: 0.0148 - val_loss: 1.9830e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 347/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.3613e-04 - mean_absolute_error: 0.0143\n",
            "Epoch 00347: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.3791e-04 - mean_absolute_error: 0.0144 - val_loss: 2.4556e-04 - val_mean_absolute_error: 0.0129\n",
            "Epoch 348/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.3990e-04 - mean_absolute_error: 0.0144\n",
            "Epoch 00348: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.3990e-04 - mean_absolute_error: 0.0144 - val_loss: 4.3737e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 349/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.6492e-04 - mean_absolute_error: 0.0148\n",
            "Epoch 00349: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.6501e-04 - mean_absolute_error: 0.0148 - val_loss: 2.7192e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 350/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.5145e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 00350: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.5004e-04 - mean_absolute_error: 0.0146 - val_loss: 2.1588e-04 - val_mean_absolute_error: 0.0119\n",
            "Epoch 351/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.2669e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00351: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.2703e-04 - mean_absolute_error: 0.0142 - val_loss: 2.0152e-04 - val_mean_absolute_error: 0.0119\n",
            "Epoch 352/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.8164e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 00352: val_loss did not improve from 0.00020\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.8205e-04 - mean_absolute_error: 0.0152 - val_loss: 2.9505e-04 - val_mean_absolute_error: 0.0144\n",
            "Epoch 353/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.5144e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 00353: val_loss improved from 0.00020 to 0.00019, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.5144e-04 - mean_absolute_error: 0.0147 - val_loss: 1.8992e-04 - val_mean_absolute_error: 0.0118\n",
            "Epoch 354/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.3071e-04 - mean_absolute_error: 0.0143\n",
            "Epoch 00354: val_loss improved from 0.00019 to 0.00018, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.3199e-04 - mean_absolute_error: 0.0143 - val_loss: 1.8064e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 355/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.4476e-04 - mean_absolute_error: 0.0144\n",
            "Epoch 00355: val_loss did not improve from 0.00018\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.4502e-04 - mean_absolute_error: 0.0144 - val_loss: 2.1518e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 356/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.5423e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 00356: val_loss did not improve from 0.00018\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.5324e-04 - mean_absolute_error: 0.0145 - val_loss: 2.0517e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 357/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.3816e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 00357: val_loss improved from 0.00018 to 0.00018, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.3785e-04 - mean_absolute_error: 0.0144 - val_loss: 1.7746e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 358/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.3306e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00358: val_loss did not improve from 0.00018\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.3451e-04 - mean_absolute_error: 0.0143 - val_loss: 2.0148e-04 - val_mean_absolute_error: 0.0115\n",
            "Epoch 359/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.4177e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 00359: val_loss did not improve from 0.00018\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.4116e-04 - mean_absolute_error: 0.0145 - val_loss: 1.9289e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 360/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.3529e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00360: val_loss improved from 0.00018 to 0.00016, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.3612e-04 - mean_absolute_error: 0.0142 - val_loss: 1.6197e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 361/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.3759e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00361: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.4001e-04 - mean_absolute_error: 0.0143 - val_loss: 1.8825e-04 - val_mean_absolute_error: 0.0117\n",
            "Epoch 362/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.4751e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 00362: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.4751e-04 - mean_absolute_error: 0.0146 - val_loss: 3.4823e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 363/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.4565e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 00363: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.4519e-04 - mean_absolute_error: 0.0145 - val_loss: 1.6403e-04 - val_mean_absolute_error: 0.0117\n",
            "Epoch 364/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.3804e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00364: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.3804e-04 - mean_absolute_error: 0.0142 - val_loss: 2.7584e-04 - val_mean_absolute_error: 0.0129\n",
            "Epoch 365/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.3341e-04 - mean_absolute_error: 0.0140\n",
            "Epoch 00365: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.3476e-04 - mean_absolute_error: 0.0141 - val_loss: 1.6387e-04 - val_mean_absolute_error: 0.0108\n",
            "Epoch 366/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 1.9530e-04 - mean_absolute_error: 0.0134\n",
            "Epoch 00366: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 1.9499e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6618e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 367/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.1811e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00367: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1780e-04 - mean_absolute_error: 0.0139 - val_loss: 1.6582e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 368/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.4672e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00368: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.4739e-04 - mean_absolute_error: 0.0142 - val_loss: 1.7213e-04 - val_mean_absolute_error: 0.0111\n",
            "Epoch 369/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.5224e-04 - mean_absolute_error: 0.0144\n",
            "Epoch 00369: val_loss did not improve from 0.00016\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.5143e-04 - mean_absolute_error: 0.0143 - val_loss: 2.6484e-04 - val_mean_absolute_error: 0.0121\n",
            "Epoch 370/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.0636e-04 - mean_absolute_error: 0.0134\n",
            "Epoch 00370: val_loss improved from 0.00016 to 0.00014, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.0555e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4361e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 371/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.4440e-04 - mean_absolute_error: 0.0140\n",
            "Epoch 00371: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.4419e-04 - mean_absolute_error: 0.0140 - val_loss: 4.5909e-04 - val_mean_absolute_error: 0.0153\n",
            "Epoch 372/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.2225e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00372: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.2225e-04 - mean_absolute_error: 0.0139 - val_loss: 1.4472e-04 - val_mean_absolute_error: 0.0104\n",
            "Epoch 373/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.2266e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00373: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.2242e-04 - mean_absolute_error: 0.0139 - val_loss: 1.6898e-04 - val_mean_absolute_error: 0.0107\n",
            "Epoch 374/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.4312e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00374: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.4410e-04 - mean_absolute_error: 0.0142 - val_loss: 1.9073e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 375/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.3304e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00375: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.3256e-04 - mean_absolute_error: 0.0142 - val_loss: 2.0805e-04 - val_mean_absolute_error: 0.0119\n",
            "Epoch 376/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.4354e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00376: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.4200e-04 - mean_absolute_error: 0.0142 - val_loss: 1.4919e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 377/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 2.0794e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00377: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.0822e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5656e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 378/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.1532e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00378: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1514e-04 - mean_absolute_error: 0.0136 - val_loss: 2.2452e-04 - val_mean_absolute_error: 0.0116\n",
            "Epoch 379/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 2.1536e-04 - mean_absolute_error: 0.0138\n",
            "Epoch 00379: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1489e-04 - mean_absolute_error: 0.0137 - val_loss: 2.2721e-04 - val_mean_absolute_error: 0.0111\n",
            "Epoch 380/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.0203e-04 - mean_absolute_error: 0.0132\n",
            "Epoch 00380: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.0169e-04 - mean_absolute_error: 0.0132 - val_loss: 2.4731e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 381/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.2907e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00381: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.2907e-04 - mean_absolute_error: 0.0139 - val_loss: 1.8698e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 382/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 2.1207e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00382: val_loss did not improve from 0.00014\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1197e-04 - mean_absolute_error: 0.0135 - val_loss: 1.9098e-04 - val_mean_absolute_error: 0.0115\n",
            "Epoch 383/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 2.0548e-04 - mean_absolute_error: 0.0133\n",
            "Epoch 00383: val_loss improved from 0.00014 to 0.00012, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.0516e-04 - mean_absolute_error: 0.0133 - val_loss: 1.2230e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 384/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.0771e-04 - mean_absolute_error: 0.0134\n",
            "Epoch 00384: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.0770e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6733e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 385/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.0852e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00385: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.0902e-04 - mean_absolute_error: 0.0136 - val_loss: 1.7250e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 386/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.0414e-04 - mean_absolute_error: 0.0132\n",
            "Epoch 00386: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.0436e-04 - mean_absolute_error: 0.0132 - val_loss: 3.2746e-04 - val_mean_absolute_error: 0.0128\n",
            "Epoch 387/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.1479e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00387: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1479e-04 - mean_absolute_error: 0.0135 - val_loss: 1.4630e-04 - val_mean_absolute_error: 0.0104\n",
            "Epoch 388/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.5156e-04 - mean_absolute_error: 0.0140\n",
            "Epoch 00388: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.5138e-04 - mean_absolute_error: 0.0140 - val_loss: 4.4749e-04 - val_mean_absolute_error: 0.0142\n",
            "Epoch 389/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.3117e-04 - mean_absolute_error: 0.0138\n",
            "Epoch 00389: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.3143e-04 - mean_absolute_error: 0.0138 - val_loss: 1.6877e-04 - val_mean_absolute_error: 0.0106\n",
            "Epoch 390/400\n",
            "438/442 [============================>.] - ETA: 0s - loss: 2.0792e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00390: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.0733e-04 - mean_absolute_error: 0.0135 - val_loss: 2.0401e-04 - val_mean_absolute_error: 0.0111\n",
            "Epoch 391/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.0375e-04 - mean_absolute_error: 0.0132\n",
            "Epoch 00391: val_loss improved from 0.00012 to 0.00012, saving model to results/2020-08-24_BBY-huber_loss-Adam-LSTM-seq-30-step-30-layers-3-units-256.h5\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 2.0375e-04 - mean_absolute_error: 0.0132 - val_loss: 1.1912e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 392/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 1.9329e-04 - mean_absolute_error: 0.0132\n",
            "Epoch 00392: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 9ms/step - loss: 1.9312e-04 - mean_absolute_error: 0.0132 - val_loss: 1.8274e-04 - val_mean_absolute_error: 0.0104\n",
            "Epoch 393/400\n",
            "437/442 [============================>.] - ETA: 0s - loss: 2.2482e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00393: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.2406e-04 - mean_absolute_error: 0.0136 - val_loss: 1.4080e-04 - val_mean_absolute_error: 0.0099\n",
            "Epoch 394/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.0218e-04 - mean_absolute_error: 0.0132\n",
            "Epoch 00394: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.0343e-04 - mean_absolute_error: 0.0132 - val_loss: 1.6767e-04 - val_mean_absolute_error: 0.0109\n",
            "Epoch 395/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 2.1836e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00395: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1837e-04 - mean_absolute_error: 0.0135 - val_loss: 2.4427e-04 - val_mean_absolute_error: 0.0115\n",
            "Epoch 396/400\n",
            "442/442 [==============================] - ETA: 0s - loss: 2.1015e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00396: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1015e-04 - mean_absolute_error: 0.0135 - val_loss: 1.7823e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 397/400\n",
            "440/442 [============================>.] - ETA: 0s - loss: 1.9530e-04 - mean_absolute_error: 0.0130\n",
            "Epoch 00397: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 1.9502e-04 - mean_absolute_error: 0.0130 - val_loss: 1.2477e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 398/400\n",
            "441/442 [============================>.] - ETA: 0s - loss: 1.8075e-04 - mean_absolute_error: 0.0129\n",
            "Epoch 00398: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 1.8110e-04 - mean_absolute_error: 0.0129 - val_loss: 1.3234e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 399/400\n",
            "436/442 [============================>.] - ETA: 0s - loss: 1.9932e-04 - mean_absolute_error: 0.0131\n",
            "Epoch 00399: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 1.9987e-04 - mean_absolute_error: 0.0131 - val_loss: 1.9571e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 400/400\n",
            "439/442 [============================>.] - ETA: 0s - loss: 2.1662e-04 - mean_absolute_error: 0.0134\n",
            "Epoch 00400: val_loss did not improve from 0.00012\n",
            "442/442 [==============================] - 4s 8ms/step - loss: 2.1591e-04 - mean_absolute_error: 0.0134 - val_loss: 1.6095e-04 - val_mean_absolute_error: 0.0099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDPdiOwNe6zn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zexTfOaDS4cU",
        "outputId": "6ac8cb21-b492-4037-8650-93318a34d3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def plot_graph(model, data):\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    plt.plot(y_test, c='b', )\n",
        "    plt.plot(y_pred, c='r')\n",
        "    plt.xlabel(\"Days\").set_color('white')\n",
        "    plt.ylabel(\"Price\").set_color('white')\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.tick_params(axis='x', colors='white')\n",
        "    plt.tick_params(axis='y', colors='white')\n",
        "    plt.show()\n",
        "\n",
        "def get_accuracy(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
        "    y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "def predict(model, data, classification=False):\n",
        "    # retrieve the last sequence from data\n",
        "    last_sequence = data[\"last_sequence\"][:N_STEPS]\n",
        "    # retrieve the column scalers\n",
        "    column_scaler = data[\"column_scaler\"]\n",
        "    # reshape the last sequence\n",
        "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
        "    # expand dimension\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "    # get the prediction (scaled from 0 to 1)\n",
        "    prediction = model.predict(last_sequence)\n",
        "    # get the price (by inverting the scaling)\n",
        "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    return predicted_price\n",
        "\n",
        "\n",
        "# load the data\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                feature_columns=FEATURE_COLUMNS, shuffle=SHUFFLE)\n",
        "\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)\n",
        "\n",
        "# evaluate the model\n",
        "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "mae = np.array([mae])\n",
        "# calculate the mean absolute error (inverse scaling)\n",
        "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform(mae.reshape(1, -1))[0][0]\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
        "# predict the future price\n",
        "future_price = predict(model, data)\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
        "#print(\"Accuracy Score:\", get_accuracy(model, data), ticker)\n",
        "plot_graph(model, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8866\n",
            "(8866, 30, 5)\n",
            "8836\n",
            "Mean Absolute Error: 1.8186575834009093\n",
            "Future price after 30 days is 76.98$\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcjMVzzDPuEj"
      },
      "source": [
        "# Resultados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ARTO2BjGYQl",
        "outputId": "6d0a72f6-fc7a-4bd7-fe92-6bc4cc34f197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "    X_test = data[\"x\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    fig = plt.figure(figsize=(9,9))\n",
        "    plt.plot(y_pred[-LOOKUP_STEP:], c='r')\n",
        "    plt.xlabel(\"Days\").set_color('blue')\n",
        "    plt.ylabel(\"Price\").set_color('blue')\n",
        "    plt.legend([\"Predicted Price: \" + ticker])\n",
        "    plt.tick_params(axis='x', colors='blue')\n",
        "    plt.tick_params(axis='y', colors='blue')\n",
        "    plt.savefig(ticker+\"_\"+date_now+'.png')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ7R8KSvCRtr"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b5fHP5GCUme",
        "outputId": "7b5ed2bd-dfc2-4d4b-88c4-eec2ec82e5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "    df = si.get_data(ticker, start_date=end_date)\n",
        "    df = df.reset_index()\n",
        "    X_test = df[\"adjclose\"]\n",
        "    fig = plt.figure(figsize=(9,9))\n",
        "    plt.plot(X_test, c='b')\n",
        "    plt.plot(y_pred[-LOOKUP_STEP:], c='r')\n",
        "    plt.xlabel(\"Days\").set_color('blue')\n",
        "    plt.ylabel(\"Price\").set_color('blue')\n",
        "    plt.tick_params(axis='x', colors='blue')\n",
        "    plt.tick_params(axis='y', colors='blue')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n_N6lShG1pD",
        "outputId": "a37b52a8-0719-457f-bd3c-b9f23b8b13f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "    X_test = data[\"x\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    fig = plt.figure(figsize=(9,9))\n",
        "    plt.plot(y_pred, c='r')\n",
        "    plt.xlabel(\"Days\").set_color('blue')\n",
        "    plt.ylabel(\"Price\").set_color('blue')\n",
        "    plt.legend([\"Predicted Price: \" + ticker])\n",
        "    plt.tick_params(axis='x', colors='blue')\n",
        "    plt.tick_params(axis='y', colors='blue')\n",
        "    plt.savefig(ticker+\"_\"+date_now+'.png')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}